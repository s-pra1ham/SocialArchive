import cv2
import os
import numpy as np

def extract_frames(video_path, output_folder, sensitivity_threshold=15, min_frames_skip=10):
    """
    Extracts frames based on Structural / Composition changes, ignoring facial movements.
    
    Args:
        sensitivity_threshold (int): (0-255). Lower = more sensitive.
                                     10-15 is usually good for ignoring faces but catching text.
        min_frames_skip (int): Minimum frames to skip after a save (prevents bursts).
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Error: Could not open video {video_path}")
        return

    # Read first frame
    ret, frame = cap.read()
    if not ret: return

    def preprocess_frame(img):
        """
        Resize and Heavy Blur to remove facial details but keep structure.
        """
        # 1. Resize to small width (speeds up processing + reduces detail)
        h, w = img.shape[:2]
        new_w = 200 # Small width forces loss of fine detail (facial expressions)
        new_h = int(h * (new_w / w))
        resized = cv2.resize(img, (new_w, new_h))
        
        # 2. Convert to Gray
        gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)
        
        # 3. HEAVY BLUR (The Magic Step)
        # Kernel size (49,49) wipes out eyes/mouth but keeps text blocks/shapes
        blurred = cv2.GaussianBlur(gray, (49, 49), 0)
        return blurred

    # Initial setup
    last_saved_frame_proc = preprocess_frame(frame)
    
    saved_count = 0
    # Save the very first frame
    cv2.imwrite(os.path.join(output_folder, f"keyframe_{saved_count:04d}.jpg"), frame)
    saved_count += 1
    
    frames_since_last_save = 0
    total_frames = 0

    while True:
        ret, frame = cap.read()
        if not ret: break
        
        frames_since_last_save += 1
        total_frames += 1

        # Skip processing if we just saved a frame (Cooldown)
        if frames_since_last_save < min_frames_skip:
            continue

        # Process current frame
        curr_frame_proc = preprocess_frame(frame)

        # Calculate Difference between CURRENT frame and LAST SAVED frame
        # (Comparing to last saved frame is crucial to detect accumulated changes)
        diff = cv2.absdiff(last_saved_frame_proc, curr_frame_proc)
        
        # Get the mean intensity of the difference
        mean_diff = np.mean(diff)

        # Check if change is significant enough
        if mean_diff > sensitivity_threshold:
            
            # Save the frame
            filename = os.path.join(output_folder, f"keyframe_{saved_count:04d}.jpg")
            cv2.imwrite(filename, frame)
            # print(f"Saved {filename} | Diff Score: {mean_diff:.2f}")

            # Update reference and reset counters
            last_saved_frame_proc = curr_frame_proc
            saved_count += 1
            frames_since_last_save = 0

    cap.release()
    print(f"Extraction complete. Saved {saved_count} keyframes from {total_frames} total in {output_folder}.")

if __name__ == "__main__":
    # --- Usage ---
    # threshold=15: Ignores talking heads, catches new text/overlays
    # min_frames_skip=10: Waits at least ~0.3 seconds between captures
    extract_frames('ingestion/video.mp4', 'artifacts/video_frames', sensitivity_threshold=15)